使用Sakura启动器，启动lamma模型。后使用ipex-llm加速lamma模型，具体如何操作加速，请github搜索ipex-llm。
模型推荐使用 0.5b qwen2
推荐使用w11自带的实时字幕识别
推荐使用团子翻译器来调用lamma模型
